{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with some imports and the utility script from the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "## this script transports l5kit and dependencies\n",
    "os.system('pip uninstall typing -y')\n",
    "os.system('pip install --target=/kaggle/working pymap3d==2.1.0')\n",
    "os.system('pip install --target=/kaggle/working protobuf==3.12.2')\n",
    "os.system('pip install --target=/kaggle/working transforms3d')\n",
    "os.system('pip install --target=/kaggle/working zarr')\n",
    "os.system('pip install --target=/kaggle/working ptable')\n",
    "\n",
    "os.system('pip install --no-dependencies --target=/kaggle/working l5kit')\n",
    "#!pip install --upgrade pip\n",
    "#!pip install pymap3d==2.1.0\n",
    "#!pip install -U l5kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing some stuff from the l5kit and setting the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DIR_INPUT = \"/home/moriarty/Downloads/lyft\"\n",
    "import os\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "SINGLE_MODE_SUBMISSION = f\"{DIR_INPUT}/single_mode_sample_submission.csv\"\n",
    "MULTI_MODE_SUBMISSION = f\"{DIR_INPUT}/multi_mode_sample_submission.csv\"\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.evaluation import write_pred_csv\n",
    "from l5kit.rasterization import build_rasterizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config File (dictionary)  from the linked notebook.  This contains parameters for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False  # True just trains for 10 steps instead of the full dataset\n",
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet50',\n",
    "        'history_num_frames': 20,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1\n",
    "    },\n",
    "    \n",
    "    'raster_params': {\n",
    "        'raster_size': [224, 224],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "    \n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 12,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 6\n",
    "    },\n",
    "    \n",
    "    'train_params': {\n",
    "        'max_num_steps': 10*1 if DEBUG else 3200,\n",
    "        'checkpoint_every_n_steps': 5000,\n",
    "        'train_batch' : 32,\n",
    "        'num_batch' : 10\n",
    "        \n",
    "        # 'eval_every_n_steps': -1\n",
    "    },\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 8,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 6\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'valid_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 8,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 6\n",
    "    },\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load In the train dataset.  I notice the pytorch folks can just import this with DataLoader, but I am not familiar with anything similar in keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "dm = LocalDataManager(None)\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Train dataset/dataloader\n",
    "\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "hist_shape = train_dataset[0]['history_positions'].shape\n",
    "num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "num_in_channels = 3 + num_history_channels\n",
    "num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path1 = dm.require(cfg[\"valid_data_loader\"][\"key\"])\n",
    "valid_zarr = ChunkedDataset(dataset_path1).open()\n",
    "valid_dataset = AgentDataset(cfg, valid_zarr, rasterizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_itr = iter(valid_dataset)\n",
    "n_valid = 100\n",
    "\n",
    "val_inputs = np.zeros(shape=(n_valid,224,224, num_in_channels) )\n",
    "val_targets = np.zeros(shape=(n_valid,num_targets))\n",
    "for itr in tqdm(range(n_valid)):\n",
    "    data = next(valid_itr)\n",
    "\n",
    "    val_inputs[itr] = data['image'].transpose(1,2,0)    \n",
    "    val_targets[itr] = data['target_positions'].reshape(-1,num_targets)\n",
    "    gc.collect()\n",
    "del valid_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 100\n",
    "plt.scatter(train_dataset[idx]['history_positions'][:,0],train_dataset[idx]['history_positions'][:,1])\n",
    "plt.scatter(train_dataset[idx]['target_positions'][:,0],train_dataset[idx]['target_positions'][:,1],c='r')\n",
    "plt.show()\n",
    "print(train_dataset[0]['target_positions'].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model architecture.\n",
    "\n",
    "Given what the examples use, lets start with ResNet50.  I tried to initialize with imagenet weights, but I get dimension mismatches, so that is something to look into.\n",
    "\n",
    "The avg pooling layer after ResNet50 will be 2048, so I add in some Dense+ BN + dropout layers, with the last one being 2xnum_targets units.\n",
    "\n",
    "First run will just use sgd optimizer with mse loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.conv_utils import convert_kernel\n",
    "from keras.layers import (Input, Conv2D, Flatten,Dense,AveragePooling2D,Dropout,MaxPooling2D,BatchNormalization)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.applications.resnet import ResNet152\n",
    "base_in = Input(shape=(224,224,num_in_channels))\n",
    "base_model=Conv2D(20,kernel_size=1,use_bias=False,padding=\"same\")(base_in)\n",
    "base_model = Dropout(0.2)(base_model)\n",
    "base_model=Conv2D(3,kernel_size=3,use_bias=False,padding=\"same\")(base_model)\n",
    "\n",
    "base_model = ResNet152(include_top=False,\n",
    "                       weights='imagenet',\n",
    "                       input_tensor=Input(shape=(224, 224, 3)),\n",
    "                       pooling='max'\n",
    "                       )(base_model)\n",
    "\n",
    "dense_model = Dense(800, activation=\"linear\")(base_model)\n",
    "dense_model = Dropout(.3)(dense_model)\n",
    "dense_model = Dense(350, activation=\"linear\")(dense_model)\n",
    "dense_model = Dropout(.3)(dense_model)\n",
    "dense_model = Dense(num_targets, activation=\"linear\")(dense_model)\n",
    "model = Model(inputs=base_in, outputs=dense_model)\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to loop through the train_dataset and use a batch_size variable to train the model in batches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "MC = ModelCheckpoint('./model.h5', verbose=True,monitor='val_loss',mode='min',\n",
    "        save_weights_only=True,save_best_only=True)\n",
    "\n",
    "stop = EarlyStopping(monitor = 'val_loss', restore_best_weights=True , patience = 5)\n",
    "\n",
    "tr_it = iter(train_dataset)\n",
    "batch_size = cfg['train_params']['train_batch']\n",
    "#progress_bar = tqdm(range(0,cfg[\"train_params\"][\"max_num_steps\"],batch_size))\n",
    "progress_bar = tqdm(range(cfg[\"train_params\"][\"max_num_steps\"]))\n",
    "two_hours = 60 * 60 * 3.1\n",
    "losses = []\n",
    "hist = []\n",
    "for itr in progress_bar:#range(0,cfg[\"train_params\"][\"max_num_steps\"],batch_size):\n",
    "    inputs = np.zeros(shape=(batch_size,224,224,num_in_channels))\n",
    "    targets = np.zeros(shape=(batch_size, num_targets))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        try:\n",
    "            data = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(train_dataset)\n",
    "            data = next(tr_it)\n",
    "            \n",
    "        inputs[i] = data['image'].transpose(1,2,0)\n",
    "        targets[i] = data['target_positions'].reshape(-1,num_targets)\n",
    "   \n",
    "    h = model.fit(inputs, targets,\n",
    "                  batch_size = int(batch_size / 2) ,\n",
    "                  validation_data = (val_inputs, val_targets),\n",
    "                  verbose = 1,\n",
    "                 callbacks = [MC, stop])\n",
    "                  \n",
    "    hist.append(h.history)\n",
    "    gc.collect()\n",
    "    # For training + submission, break if training exceeds 6 hours\n",
    "    if (time.time()-t0) > two_hours:\n",
    "        break\n",
    "    \n",
    "    \n",
    "vl = [hi['val_loss'] for hi in hist]\n",
    "l = [hi['loss'] for hi in hist]\n",
    "plt.plot(np.log(vl), label = 'val_loss')\n",
    "plt.plot(np.log(l), label = 'loss')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelv0.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.utils.conv_utils import convert_kernel\n",
    "from keras.layers import (Input, Conv2D, Flatten,Dense,AveragePooling2D,Dropout,MaxPooling2D,BatchNormalization)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.applications.resnet import ResNet101\n",
    "# load model\n",
    "model = load_model('modelv0.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Prediction:\n",
    "import matplotlib.pyplot as plt\n",
    "tr_it = iter(train_dataset)\n",
    "a1 = next(tr_it)\n",
    "inp = a1['image'].transpose(1,2,0)\n",
    "act = a1['target_positions']\n",
    "pred = model.predict(inp.reshape(-1,224,224,num_in_channels)).reshape(50,2)\n",
    "plt.scatter(act[:,0], act[:,1])\n",
    "plt.scatter(pred[:,0],pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this model to predict from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cfg = cfg[\"test_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Test dataset/dataloader\n",
    "test_zarr = ChunkedDataset(dm.require(test_cfg[\"key\"])).open()\n",
    "test_mask = np.load(f\"{DIR_INPUT}/scenes/mask.npz\")[\"arr_0\"]\n",
    "test_dataset = AgentDataset(cfg, test_zarr, rasterizer, agents_mask=test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "#data_pairs = [ [3,5], [4,3], [7,3], [1,6] ]\n",
    "#need to chunk my test dataset \n",
    "t_shape = test_dataset[0][\"target_positions\"].shape\n",
    "def predictor():\n",
    "    valid_itr = iter(test_dataset)\n",
    "    n_valid = 30000\n",
    "    timestamps = []\n",
    "    agent_ids = []\n",
    "    coords = []\n",
    "    for image in tqdm(range(30000)):\n",
    "        it = next(valid_itr)\n",
    "        dat = it['image'].transpose(1,2,0)\n",
    "        coords.append(np.array(model.predict(dat.reshape(1,224,224,num_in_channels)).reshape(t_shape)))\n",
    "        timestamps.append(it[\"timestamp\"])\n",
    "        agent_ids.append(it[\"track_id\"])\n",
    "        print('1')\n",
    "    some_list = [timestamps, agent_ids, coords]\n",
    "    return some_list\n",
    "def predictor1():\n",
    "    valid_itr = iter(test_dataset)\n",
    "    n_valid = 30000\n",
    "    timestamps = []\n",
    "    agent_ids = []\n",
    "    coords = []\n",
    "    for image in tqdm(range(30000,len(test_dataset))):\n",
    "        it = next(valid_itr)\n",
    "        dat = it['image'].transpose(1,2,0)\n",
    "        coords.append(np.array(model.predict(dat.reshape(1,224,224,num_in_channels)).reshape(t_shape)))\n",
    "        timestamps.append(it[\"timestamp\"])\n",
    "        agent_ids.append(it[\"track_id\"])\n",
    "        print('2')\n",
    "    some_list = [timestamps, agent_ids, coords]\n",
    "    return some_list\n",
    "\n",
    "def smap(f):\n",
    "    return f()\n",
    "pool = Pool(processes=2)\n",
    "res = pool.map(smap,[predictor, predictor1])\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_shape = test_dataset[0][\"target_positions\"].shape\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "coords = []\n",
    "for it in tqdm(test_dataset):\n",
    "    \n",
    "    dat = it['image'].transpose(1,2,0)\n",
    "    coords.append(np.array(model.predict(dat.reshape(1,224,224,num_in_channels)).reshape(t_shape)))\n",
    "    timestamps.append(it[\"timestamp\"])\n",
    "    agent_ids.append(it[\"track_id\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.evaluation import write_pred_csv\n",
    "\n",
    "\n",
    "write_pred_csv('submission.csv',\n",
    "                timestamps = np.array(timestamps),\n",
    "                track_ids = np.array(agent_ids),\n",
    "                coords = np.array(coords) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
